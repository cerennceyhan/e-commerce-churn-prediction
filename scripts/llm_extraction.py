"""
==================================================================================
LLM Ä°LE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄÄ° (CLAUDE 4.5 SONNET)
==================================================================================
"""

import pandas as pd
import json
import anthropic
import time
from tqdm import tqdm
import os

class LLMFeatureExtractor:
    """
    Claude 4.5 Sonnet kullanarak Ã¼rÃ¼n yorumlarÄ±ndan Ã¶zellik Ã§Ä±karma
    Her Ã¼rÃ¼n iÅŸlenince anÄ±nda kaydeder!
    """
    
    def __init__(self, original_csv_path, product_features_csv_path, output_path, api_key):
        # Orijinal yorumlarÄ± yÃ¼kle
        self.df_reviews = pd.read_csv(original_csv_path, encoding='utf-8-sig')
        
        # Parse tarihleri
        self._parse_dates()
        
        # ÃœrÃ¼n Ã¶zelliklerini yÃ¼kle (Phase 1 Ã§Ä±ktÄ±sÄ±)
        self.df_products = pd.read_csv(product_features_csv_path)
        
        # Claude client
        self.client = anthropic.Anthropic(api_key=api_key)
        
        # Output dosya yolu
        self.output_path = output_path
        
        # Ä°ÅŸlenmiÅŸ Ã¼rÃ¼nleri takip et
        self.processed_products = self._load_processed_products()
        
    def _parse_dates(self):
        """Tarihleri parse et"""
        month_mapping = {
            'Ocak': 'January', 'Åubat': 'February', 'Mart': 'March',
            'Nisan': 'April', 'MayÄ±s': 'May', 'Haziran': 'June',
            'Temmuz': 'July', 'AÄŸustos': 'August', 'EylÃ¼l': 'September',
            'Ekim': 'October', 'KasÄ±m': 'November', 'AralÄ±k': 'December'
        }
        
        def convert_date(date_str):
            if pd.isna(date_str):
                return None
            for tr, en in month_mapping.items():
                date_str = date_str.replace(tr, en)
            try:
                return pd.to_datetime(date_str, format='%d %B %Y')
            except:
                return None
        
        self.df_reviews['parsed_date'] = self.df_reviews['Tarih'].apply(convert_date)
        self.df_reviews = self.df_reviews.dropna(subset=['parsed_date'])
    
    def _load_processed_products(self):
        """
        Daha Ã¶nce iÅŸlenmiÅŸ Ã¼rÃ¼nleri yÃ¼kle (kaldÄ±ÄŸÄ± yerden devam iÃ§in)
        """
        if os.path.exists(self.output_path):
            df_existing = pd.read_csv(self.output_path)
            processed = set(df_existing['ÃœrÃ¼n'].unique())
            print(f"ğŸ“‚ Mevcut dosya bulundu: {len(processed)} Ã¼rÃ¼n zaten iÅŸlenmiÅŸ")
            return processed
        return set()
    
    def _calculate_risk_class(self, row_dict):
        """
        Tek bir Ã¼rÃ¼n iÃ§in Risk_Class VE Risk_Score hesapla
        Returns: (risk_class, risk_score)
        """
        # Phase 1'den Toplam_Yorum_Sayisi al
        product_name = row_dict.get('ÃœrÃ¼n')
        product_info = self.df_products[self.df_products['ÃœrÃ¼n'] == product_name]
        
        if len(product_info) == 0:
            return 0, 0  # Default: Healthy, score 0
        
        toplam_yorum = product_info['Toplam_Yorum_Sayisi'].iloc[0]
        
        # 1. ENGAGEMENT CHURN (az yorum)
        if toplam_yorum < 5:
            return 2, 0  # Engagement churn, score 0 (yorum yetersiz)
        
        # 2. QUALITY CHURN (LLM Ã¶zellikleri)
        quality_risk = 0
        
        # KalÄ±p problemi VAR ve ciddi
        if row_dict.get('fitment_problem') == True and row_dict.get('fitment_severity', 0) >= 7:
            quality_risk += 3
        elif row_dict.get('fitment_problem') == True:
            quality_risk += 1
        
        # KumaÅŸ kalitesi problemi VAR
        if row_dict.get('fabric_quality_issue') == True:
            quality_risk += 2
        
        # LLM kalite algÄ±sÄ± dÃ¼ÅŸÃ¼k
        quality_sentiment = row_dict.get('quality_sentiment', 5)
        if quality_sentiment <= 2:
            quality_risk += 3
        elif quality_sentiment == 3:
            quality_risk += 1
        
        # Teslimat problemi VAR
        if row_dict.get('delivery_issue') == True:
            quality_risk += 1
        
        # 3. SINIFLANDIRMA
        if quality_risk >= 4:
            return 1, quality_risk  # Quality Churn, score
        else:
            return 0, quality_risk  # Healthy, score
    
    def _save_single_result(self, result_dict):
        """
        TEK BÄ°R Ã¼rÃ¼nÃ¼n sonucunu ANINDA kaydet!
        """
        # Risk_Class ve Risk_Score hesapla ve ekle
        risk_class, risk_score = self._calculate_risk_class(result_dict)
        result_dict['Risk_Class'] = risk_class
        result_dict['Risk_Score'] = risk_score
        
        # Yeni satÄ±rÄ± DataFrame'e Ã§evir
        new_row = pd.DataFrame([result_dict])
        
        # Dosya varsa append, yoksa create
        if os.path.exists(self.output_path):
            # Mevcut veriyi oku
            df_existing = pd.read_csv(self.output_path)
            # Yeni satÄ±rÄ± ekle
            df_updated = pd.concat([df_existing, new_row], ignore_index=True)
            # Kaydet
            df_updated.to_csv(self.output_path, index=False, encoding='utf-8-sig')
        else:
            # Ä°lk kez oluÅŸtur
            new_row.to_csv(self.output_path, index=False, encoding='utf-8-sig')
    
    def extract_product_comments(self, product_name, max_comments=100):
        """
        Bir Ã¼rÃ¼ne ait yorumlarÄ± Ã§ek
        Son yorumlara Ã¶ncelik ver (daha gÃ¼ncel trendler)
        """
        product_reviews = self.df_reviews[
            self.df_reviews['ÃœrÃ¼n'] == product_name
        ].sort_values('parsed_date', ascending=False).head(max_comments)
        
        return product_reviews['duzeltilmis_yorum'].tolist()
    
    def create_llm_prompt(self, comments_list):
        """
        Claude iÃ§in DÃœZELTÄ°LMÄ°Å prompt - Bilimsel eÅŸiklerle
        """
        # YorumlarÄ± birleÅŸtir
        comments_text = "\n".join([f"- {comment}" for comment in comments_list if str(comment) != 'HATA' and pd.notna(comment)])
        
        prompt = f"""Bir e-ticaret Ã¼rÃ¼nÃ¼ne ait kullanÄ±cÄ± yorumlarÄ±nÄ± analiz ediyorsun. GÃ¶revin, GENEL eÄŸilimi belirlemek (birkaÃ§ aykÄ±rÄ± yorumu deÄŸil).

YORUMLAR:
{comments_text}

AÅŸaÄŸÄ±daki bilgileri JSON formatÄ±nda Ã§Ä±kar. SADECE JSON Ã§Ä±ktÄ±sÄ± ver, baÅŸka aÃ§Ä±klama ekleme:

{{
  "fitment_problem": true/false,
  "fitment_severity": 0-10,
  "quality_sentiment": 1-5,
  "delivery_issue": true/false,
  "color_mismatch": true/false,
  "main_complaint": "string",
  "fabric_quality_issue": true/false,
  "price_value_perception": 1-5
}}

KRÄ°TÄ°K KURALLAR - Ã‡OK Ã–NEMLÄ°:

1. fitment_problem: SADECE yorumlarÄ±n %20'sinden FAZLASI (5'te 1'i) beden/kalÄ±p problemi belirtiyorsa TRUE. 
   Ã–rnek: 100 yorumda 20'den fazlasÄ± "bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k/bol/dar" diyorsa TRUE, deÄŸilse FALSE.

2. fabric_quality_issue: SADECE yorumlarÄ±n %20'sinden FAZLASI kumaÅŸ kalitesinden ÅŸikayet ediyorsa TRUE.
   Ã–rnek: 100 yorumda 20'den fazlasÄ± "kumaÅŸ kÃ¶tÃ¼/ince/kalitesiz" diyorsa TRUE, deÄŸilse FALSE.

3. delivery_issue: SADECE yorumlarÄ±n %20'sinden FAZLASI teslimat sorunu belirtiyorsa TRUE.

4. color_mismatch: SADECE yorumlarÄ±n %20'sinden FAZLASI renk uyumsuzluÄŸu belirtiyorsa TRUE.

5. quality_sentiment: Ã‡OÄUNLUÄUN genel kalite algÄ±sÄ±nÄ± yansÄ±t.
   - Ã‡oÄŸunluk "mÃ¼kemmel/harika/kaliteli" diyorsa â†’ 5
   - Ã‡oÄŸunluk "iyi/gÃ¼zel" diyorsa â†’ 4
   - Ã‡oÄŸunluk "orta" diyorsa â†’ 3
   - Ã‡oÄŸunluk "kÃ¶tÃ¼" diyorsa â†’ 2
   - Ã‡oÄŸunluk "berbat" diyorsa â†’ 1

6. main_complaint: En sÄ±k tekrarlanan ciddi ÅŸikayeti yaz. EÄŸer ciddi ÅŸikayet yoksa "Genel memnuniyet yÃ¼ksek" yaz.

7. fitment_severity & price_value_perception: 0-10 arasÄ±, GENEL eÄŸilimi yansÄ±t.

Ã–RNEKLER:

Senaryo 1:
- 100 yorum
- 95 kiÅŸi: "MÃ¼kemmel, harika, bayÄ±ldÄ±m"
- 3 kiÅŸi: "Beden bÃ¼yÃ¼k geldi"
- 2 kiÅŸi: "KumaÅŸ ince"
â†’ fitment_problem: FALSE (%3 < %20)
â†’ fabric_quality_issue: FALSE (%2 < %20)
â†’ quality_sentiment: 5
â†’ main_complaint: "Genel memnuniyet yÃ¼ksek"

Senaryo 2:
- 100 yorum
- 30 kiÅŸi: "Beden Ã§ok bÃ¼yÃ¼k, kalÄ±p kÃ¶tÃ¼"
- 70 kiÅŸi: "GÃ¼zel Ã¼rÃ¼n"
â†’ fitment_problem: TRUE (%30 > %20)
â†’ fitment_severity: 7 (ciddi problem)
â†’ quality_sentiment: 4 (Ã§oÄŸunluk memnun)
â†’ main_complaint: "Beden bÃ¼yÃ¼k geliyor"

SADECE YAYGIN SORUNLARI RAPORLA! BirkaÃ§ kiÅŸinin sÃ¶ylemesi SORUN DEÄÄ°LDÄ°R."""

        return prompt
    
    def call_llm_api(self, prompt, model="claude-sonnet-4-5-20250929"):
        """
        Claude API'ye istek gÃ¶nder
        """
        try:
            response = self.client.messages.create(
                model=model,
                max_tokens=1024,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # Response'u temizle
            response_text = response.content[0].text.strip()
            
            # Markdown code block temizliÄŸi
            if response_text.startswith("```json"):
                response_text = response_text[7:]
            if response_text.startswith("```"):
                response_text = response_text[3:]
            if response_text.endswith("```"):
                response_text = response_text[:-3]
            
            response_text = response_text.strip()
            
            # JSON parse et
            result = json.loads(response_text)
            return result
        
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON parse hatasÄ±: {e}")
            return None
        except Exception as e:
            print(f"âš ï¸ API hatasÄ±: {e}")
            return None
    
    def process_all_products(self, max_products=None, delay=1.0):
        """
        TÃ¼m Ã¼rÃ¼nler iÃ§in LLM Ã¶zelliklerini Ã§Ä±kar
        HER ÃœRÃœN Ä°ÅLENÄ°NCE ANINDA KAYDEDER!
        """
        products = self.df_products['ÃœrÃ¼n'].tolist()
        
        # Sadece iÅŸlenmemiÅŸ Ã¼rÃ¼nleri al
        products_to_process = [p for p in products if p not in self.processed_products]
        
        if max_products:
            products_to_process = products_to_process[:max_products]
        
        print(f"\nğŸ¤– LLM Ã¶zellik Ã§Ä±karma baÅŸlÄ±yor...")
        print(f"   Toplam Ã¼rÃ¼n: {len(products)}")
        print(f"   Zaten iÅŸlenmiÅŸ: {len(self.processed_products)}")
        print(f"   Ä°ÅŸlenecek: {len(products_to_process)}")
      
        
        if len(products_to_process) == 0:
            print("\nâœ… TÃ¼m Ã¼rÃ¼nler zaten iÅŸlenmiÅŸ!")
            return
        
        success_count = 0
        
        for product_name in tqdm(products_to_process, desc="Processing"):
            # YorumlarÄ± Ã§ek
            comments = self.extract_product_comments(product_name)
            
            if len(comments) == 0:
                print(f"âš ï¸ {product_name[:50]} iÃ§in yorum bulunamadÄ±")
                continue
            
            # Claude'a gÃ¶nder
            prompt = self.create_llm_prompt(comments)
            llm_result = self.call_llm_api(prompt)
            
            if llm_result:
                # ÃœrÃ¼n bilgilerini ekle
                llm_result['ÃœrÃ¼n'] = product_name
                llm_result['Yorum_Sayisi'] = len(comments)
                
                # ANINDA KAYDET! ğŸ’¾
                self._save_single_result(llm_result)
                
                # Ä°ÅŸlenmiÅŸ olarak iÅŸaretle
                self.processed_products.add(product_name)
                success_count += 1
            
            # Rate limit
            time.sleep(delay)
        
        print(f"\nâœ… {success_count} Ã¼rÃ¼n iÃ§in LLM Ã¶zellikleri Ã§Ä±karÄ±ldÄ± ve kaydedildi")
    
    def merge_with_product_features(self):
        """
        LLM Ã¶zelliklerini Phase 1'deki Ã¶zelliklerle birleÅŸtir
        """
        if not os.path.exists(self.output_path):
            print("âš ï¸ HenÃ¼z hiÃ§ Ã¼rÃ¼n iÅŸlenmemiÅŸ!")
            return None
        
        # LLM sonuÃ§larÄ±nÄ± oku
        df_llm = pd.read_csv(self.output_path)
        
        # Phase 1 ile birleÅŸtir
        df_final = self.df_products.merge(
            df_llm,
            on='ÃœrÃ¼n',
            how='left'
        )
        
        return df_final
    
    def create_risk_class(self, df):
        """
        Risk_Class ve Risk_Score oluÅŸtur (SADECE LLM Ã¶zellikleriyle)
        """
        def classify_product(row):
            # 1. ENGAGEMENT CHURN (az yorum)
            if row['Toplam_Yorum_Sayisi'] < 5:
                return 2, 0  # Engagement churn, score 0
            
            # 2. QUALITY CHURN (LLM Ã¶zellikleri)
            quality_risk = 0
            
            # KalÄ±p problemi VAR ve ciddi
            if row['fitment_problem'] == True and row['fitment_severity'] >= 7:
                quality_risk += 3
            elif row['fitment_problem'] == True:
                quality_risk += 1
            
            # KumaÅŸ kalitesi problemi VAR
            if row['fabric_quality_issue'] == True:
                quality_risk += 2
            
            # LLM kalite algÄ±sÄ± dÃ¼ÅŸÃ¼k
            if row['quality_sentiment'] <= 2:
                quality_risk += 3
            elif row['quality_sentiment'] == 3:
                quality_risk += 1
            
            # Teslimat problemi VAR
            if row['delivery_issue'] == True:
                quality_risk += 1
            
            # 3. SINIFLANDIRMA
            if quality_risk >= 4:
                return 1, quality_risk  # Quality Churn
            else:
                return 0, quality_risk  # Healthy
        
        # Her satÄ±r iÃ§in hem class hem score hesapla
        results = df.apply(classify_product, axis=1)
        df['Risk_Class'] = results.apply(lambda x: x[0])
        df['Risk_Score'] = results.apply(lambda x: x[1])
        
        # DaÄŸÄ±lÄ±mÄ± gÃ¶ster
        risk_dist = df['Risk_Class'].value_counts().sort_index()
        print(f"\nğŸ“Š HEDEF DEÄÄ°ÅKEN DAÄILIMI:")
        print(f"   Healthy (0):          {risk_dist.get(0, 0)} Ã¼rÃ¼n ({risk_dist.get(0, 0)/len(df)*100:.1f}%)")
        print(f"   Quality Churn (1):    {risk_dist.get(1, 0)} Ã¼rÃ¼n ({risk_dist.get(1, 0)/len(df)*100:.1f}%)")
        print(f"   Engagement Churn (2): {risk_dist.get(2, 0)} Ã¼rÃ¼n ({risk_dist.get(2, 0)/len(df)*100:.1f}%)")
        
        print(f"\nğŸ“Š RISK_SCORE Ä°STATÄ°STÄ°KLERÄ°:")
        print(f"   Ortalama: {df['Risk_Score'].mean():.2f}")
        print(f"   Min: {df['Risk_Score'].min()}")
        print(f"   Max: {df['Risk_Score'].max()}")
        
        return df
    
    def finalize_and_save(self, final_output_path):
        """
        TÃ¼m iÅŸlem bittikten sonra final dosyayÄ± oluÅŸtur
        """
        df_final = self.merge_with_product_features()
        
        if df_final is not None:
            # Risk_Class ekle
            df_final = self.create_risk_class(df_final)
            
            df_final.to_csv(final_output_path, index=False, encoding='utf-8-sig')
            
            print(f"\nğŸ’¾ Final veri kaydedildi: {final_output_path}")
            print(f"\nğŸ“Š TOPLAM Ã–ZELLÄ°K SAYISI: {len(df_final.columns)}")
            print("\nğŸ” LLM Ã–ZELLÄ°KLERÄ°:")
            llm_cols = ['fitment_problem', 'quality_sentiment', 'delivery_issue', 
                        'main_complaint', 'fabric_quality_issue', 'price_value_perception']
            for col in llm_cols:
                if col in df_final.columns:
                    print(f"   âœ“ {col}")
            
            print(f"\nâœ“ Risk_Class eklendi!")
            
            return df_final
        
        return None


# ============================================================================
# KULLANIM Ã–RNEÄÄ°
# ============================================================================
if __name__ == "__main__":
    print("=" * 80)
    print("PHASE 2: LLM Ä°LE Ã–ZELLÄ°K MÃœHENDÄ°SLÄ°ÄÄ°")
    print("=" * 80)
    
    # API Key'i environment variable'dan al, yoksa kullanÄ±cÄ±dan iste
    CLAUDE_API_KEY = os.environ.get('CLAUDE_API_KEY')
    if not CLAUDE_API_KEY:
        print("\nâš ï¸ CLAUDE_API_KEY environment variable bulunamadÄ±!")
        print("LÃ¼tfen API key'inizi girin (veya CLAUDE_API_KEY environment variable'Ä±nÄ± ayarlayÄ±n):")
        CLAUDE_API_KEY = input("API Key: ").strip()
    
    # Proje kÃ¶k dizinini bul
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    
    # Dosya yollarÄ±nÄ± gÃ¶receli olarak oluÅŸtur
    RAW_DATA = os.path.join(project_root, 'data', 'raw', 'sample_dataset.csv')
    PHASE1_DATA = os.path.join(project_root, 'data', 'processed', 'base_metrics.csv')
    TEMP_OUTPUT = os.path.join(project_root, 'data', 'processed', 'llm_results.csv')
    FINAL_OUTPUT = os.path.join(project_root, 'data', 'processed', 'llm_extraction.csv')
    
    # 1. SÄ±nÄ±fÄ± baÅŸlat
    extractor = LLMFeatureExtractor(
        original_csv_path=RAW_DATA,
        product_features_csv_path=PHASE1_DATA,
        output_path=TEMP_OUTPUT,
        api_key=CLAUDE_API_KEY
    )
    
    # 2. LLM ile Ã¶zellik Ã§Ä±kar
    extractor.process_all_products(
        max_products=None,  # Hepsini iÅŸle
        delay=1.0
    )
    
    # 3. Final dosyayÄ± oluÅŸtur (Risk_Class ile)
    df_final = extractor.finalize_and_save(FINAL_OUTPUT)
    
    print("\n" + "=" * 80)
    print("âœ…TAMAMLANDI!")
    print("=" * 80)